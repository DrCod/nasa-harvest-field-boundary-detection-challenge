{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 96.268048,
      "end_time": "2023-01-07T03:31:42.238874",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-01-07T03:30:05.970826",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies\n",
        "\n",
        "All the dependencies for this notebook to run on colab are included in the `requirements_colab.txt` file included in this folder. To run the model on GPU you should go to edit/notebook settings and select GPU"
      ],
      "metadata": {
        "id": "14d67bbe",
        "papermill": {
          "duration": 0.010889,
          "end_time": "2023-01-07T03:30:14.838674",
          "exception": false,
          "start_time": "2023-01-07T03:30:14.827785",
          "status": "completed"
        },
        "tags": []
      },
      "id": "14d67bbe"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r 'https://raw.githubusercontent.com/radiantearth/Nasa_harvest_field_boundary_competition/main/requirements_colab.txt'"
      ],
      "metadata": {
        "id": "9a7a4b2f",
        "papermill": {
          "duration": 76.811881,
          "end_time": "2023-01-07T03:31:31.662052",
          "exception": false,
          "start_time": "2023-01-07T03:30:14.850171",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:04:24.326204Z",
          "iopub.execute_input": "2023-02-25T00:04:24.326627Z",
          "iopub.status.idle": "2023-02-25T00:05:45.784907Z",
          "shell.execute_reply.started": "2023-02-25T00:04:24.326538Z",
          "shell.execute_reply": "2023-02-25T00:05:45.783668Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "9a7a4b2f"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "id": "EDfN2whLeyz3",
        "execution": {
          "iopub.status.busy": "2023-02-25T00:05:45.787726Z",
          "iopub.execute_input": "2023-02-25T00:05:45.788470Z",
          "iopub.status.idle": "2023-02-25T00:05:56.242960Z",
          "shell.execute_reply.started": "2023-02-25T00:05:45.788430Z",
          "shell.execute_reply": "2023-02-25T00:05:56.241823Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "EDfN2whLeyz3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the needed libraries\n",
        "import getpass\n",
        "import glob\n",
        "import keras\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import shutil\n",
        "from radiant_mlhub import Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio as rio\n",
        "\n",
        "import tensorflow as tf\n",
        "import segmentation_models as sm\n",
        "\n",
        "from pathlib import Path\n",
        "from radiant_mlhub import Dataset\n",
        "from random import choice\n",
        "from segmentation_models import Unet\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import *\n",
        "from keras.preprocessing import image\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.losses import *\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tensorflow.python.keras.backend import resize_images\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import cv2\n",
        "import gc\n",
        "\n",
        "\n",
        "from typing import List, Any, Callable, Tuple"
      ],
      "metadata": {
        "id": "784f0b35",
        "papermill": {
          "duration": 6.824974,
          "end_time": "2023-01-07T03:31:38.518664",
          "exception": false,
          "start_time": "2023-01-07T03:31:31.693690",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:06.724056Z",
          "iopub.execute_input": "2023-02-25T00:06:06.724592Z",
          "iopub.status.idle": "2023-02-25T00:06:12.780345Z",
          "shell.execute_reply.started": "2023-02-25T00:06:06.724543Z",
          "shell.execute_reply": "2023-02-25T00:06:12.779372Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "784f0b35"
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 2023\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything(seed=2023)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:12.781642Z",
          "iopub.execute_input": "2023-02-25T00:06:12.784370Z",
          "iopub.status.idle": "2023-02-25T00:06:12.792230Z",
          "shell.execute_reply.started": "2023-02-25T00:06:12.784340Z",
          "shell.execute_reply": "2023-02-25T00:06:12.791101Z"
        },
        "trusted": true,
        "id": "aLnU5MR1RmnX"
      },
      "execution_count": null,
      "outputs": [],
      "id": "aLnU5MR1RmnX"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_id = 'nasa_rwanda_field_boundary_competition'\n",
        "assets = ['labels']"
      ],
      "metadata": {
        "id": "04dfcd1f",
        "papermill": {
          "duration": 0.043793,
          "end_time": "2023-01-07T03:31:38.596187",
          "exception": false,
          "start_time": "2023-01-07T03:31:38.552394",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:12.793682Z",
          "iopub.execute_input": "2023-02-25T00:06:12.794214Z",
          "iopub.status.idle": "2023-02-25T00:06:12.801832Z",
          "shell.execute_reply.started": "2023-02-25T00:06:12.794173Z",
          "shell.execute_reply": "2023-02-25T00:06:12.800913Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "04dfcd1f"
    },
    {
      "cell_type": "code",
      "source": [
        "#Append your MLHUB_API_KEY after this cell is executed to download dataset\n",
        "os.environ['MLHUB_API_KEY'] = getpass.getpass(prompt=\"MLHub API Key: \")\n",
        "dataset = Dataset.fetch(dataset_id)"
      ],
      "metadata": {
        "id": "84c3e1a7",
        "papermill": {
          "duration": 0.427372,
          "end_time": "2023-01-07T03:31:39.056844",
          "exception": true,
          "start_time": "2023-01-07T03:31:38.629472",
          "status": "failed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:12.802951Z",
          "iopub.execute_input": "2023-02-25T00:06:12.803753Z",
          "iopub.status.idle": "2023-02-25T00:06:13.112159Z",
          "shell.execute_reply.started": "2023-02-25T00:06:12.803699Z",
          "shell.execute_reply": "2023-02-25T00:06:13.111285Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "84c3e1a7"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.download(output_dir = dataset_id, if_exists='overwrite')"
      ],
      "metadata": {
        "id": "07aabe2e",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:13.115801Z",
          "iopub.execute_input": "2023-02-25T00:06:13.116083Z",
          "iopub.status.idle": "2023-02-25T00:06:16.129746Z",
          "shell.execute_reply.started": "2023-02-25T00:06:13.116057Z",
          "shell.execute_reply": "2023-02-25T00:06:16.128624Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "07aabe2e"
    },
    {
      "cell_type": "code",
      "source": [
        "archives = ['source_train', 'source_test', 'labels_train']"
      ],
      "metadata": {
        "id": "72678f92",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:16.131868Z",
          "iopub.execute_input": "2023-02-25T00:06:16.132266Z",
          "iopub.status.idle": "2023-02-25T00:06:16.138888Z",
          "shell.execute_reply.started": "2023-02-25T00:06:16.132228Z",
          "shell.execute_reply": "2023-02-25T00:06:16.137383Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "72678f92"
    },
    {
      "cell_type": "code",
      "source": [
        "for archive in archives:\n",
        "    full_path = f\"{dataset_id}/{dataset_id}_{archive}.tar.gz\"\n",
        "    shutil.unpack_archive(full_path, dataset_id)"
      ],
      "metadata": {
        "id": "efb328a7",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:16.143897Z",
          "iopub.execute_input": "2023-02-25T00:06:16.144277Z",
          "iopub.status.idle": "2023-02-25T00:06:18.970896Z",
          "shell.execute_reply.started": "2023-02-25T00:06:16.144250Z",
          "shell.execute_reply": "2023-02-25T00:06:18.969781Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "efb328a7"
    },
    {
      "cell_type": "code",
      "source": [
        "#image snapshot dimensions\n",
        "IMG_WIDTH = 256 \n",
        "IMG_HEIGHT = 256 \n",
        "IMG_CHANNELS = 4 #we have the rgba bands"
      ],
      "metadata": {
        "id": "165c6449",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:18.972628Z",
          "iopub.execute_input": "2023-02-25T00:06:18.973119Z",
          "iopub.status.idle": "2023-02-25T00:06:18.979367Z",
          "shell.execute_reply.started": "2023-02-25T00:06:18.972982Z",
          "shell.execute_reply": "2023-02-25T00:06:18.978091Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "165c6449"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have two sets of data: the train and test dataset, each having a list of file ids belonging to them.\n",
        "For model development purposes, we will use the training set(`train_tiles`) and use the test set for model prediction/evaluation."
      ],
      "metadata": {
        "id": "70785270",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "id": "70785270"
    },
    {
      "cell_type": "code",
      "source": [
        "train_source_items = f\"{dataset_id}/{dataset_id}_source_train\"\n",
        "train_label_items = f\"{dataset_id}/{dataset_id}_labels_train\""
      ],
      "metadata": {
        "id": "c8632119",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:18.980741Z",
          "iopub.execute_input": "2023-02-25T00:06:18.981436Z",
          "iopub.status.idle": "2023-02-25T00:06:19.023181Z",
          "shell.execute_reply.started": "2023-02-25T00:06:18.981396Z",
          "shell.execute_reply": "2023-02-25T00:06:19.021837Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "c8632119"
    },
    {
      "cell_type": "code",
      "source": [
        "next(os.walk(train_source_items))[1][0]"
      ],
      "metadata": {
        "id": "c86f51da",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f33c97f1-7b62-438b-8f43-ae68fa82e29b",
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:19.024601Z",
          "iopub.execute_input": "2023-02-25T00:06:19.025421Z",
          "iopub.status.idle": "2023-02-25T00:06:19.038332Z",
          "shell.execute_reply.started": "2023-02-25T00:06:19.025377Z",
          "shell.execute_reply": "2023-02-25T00:06:19.037071Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nasa_rwanda_field_boundary_competition_source_train_50_2021_10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "id": "c86f51da"
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_string(s: str) -> str:\n",
        "    \"\"\"\n",
        "    extract the tile id and timestamp from a source image folder\n",
        "    e.g extract 'ID_YYYY_MM' from 'nasa_rwanda_field_boundary_competition_source_train_ID_YYYY_MM'\n",
        "    \"\"\"\n",
        "    s = s.replace(f\"{dataset_id}_source_\", '').split('_')[1:]\n",
        "    return '_'.join(s)"
      ],
      "metadata": {
        "id": "bbd6d50c",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:19.042094Z",
          "iopub.execute_input": "2023-02-25T00:06:19.042408Z",
          "iopub.status.idle": "2023-02-25T00:06:19.048676Z",
          "shell.execute_reply.started": "2023-02-25T00:06:19.042383Z",
          "shell.execute_reply": "2023-02-25T00:06:19.047273Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "bbd6d50c"
    },
    {
      "cell_type": "code",
      "source": [
        "train_tiles = [clean_string(s) for s in next(os.walk(train_source_items))[1]]"
      ],
      "metadata": {
        "id": "82e08aec",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:19.050289Z",
          "iopub.execute_input": "2023-02-25T00:06:19.050834Z",
          "iopub.status.idle": "2023-02-25T00:06:19.060338Z",
          "shell.execute_reply.started": "2023-02-25T00:06:19.050801Z",
          "shell.execute_reply": "2023-02-25T00:06:19.059377Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "82e08aec"
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the 4 bands of the image\n",
        "tile = random.choice(train_tiles)\n",
        "print(tile)\n",
        "bd1 = rio.open(f\"{train_source_items}/{dataset_id}_source_train_{tile}/B01.tif\")\n",
        "bd1_array = bd1.read(1)\n",
        "bd2 = rio.open(f\"{train_source_items}/{dataset_id}_source_train_{tile}/B02.tif\")\n",
        "bd2_array = bd2.read(1)\n",
        "bd3 = rio.open(f\"{train_source_items}/{dataset_id}_source_train_{tile}/B03.tif\")\n",
        "bd3_array = bd3.read(1)\n",
        "bd4 = rio.open(f\"{train_source_items}/{dataset_id}_source_train_{tile}/B04.tif\")\n",
        "bd4_array = bd4.read(1)\n",
        "\n",
        "field = np.dstack((bd4_array, bd3_array, bd2_array, bd1_array))\n",
        "\n",
        "field = np.sqrt(field)\n",
        "\n",
        "#data standardization\n",
        "for c in range(field.shape[2]):\n",
        "    mean = field[:, :, c].mean()\n",
        "    std = field[:, :, c].std()\n",
        "    field[:, :, c] = (field[:, :, c] - mean) / std\n",
        "\n",
        "\n",
        "mask  = rio.open(Path.cwd() / f\"{train_label_items}/{dataset_id}_labels_train_{tile.split('_')[0]}/raster_labels.tif\").read(1)"
      ],
      "metadata": {
        "id": "206f3d63",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:19.436580Z",
          "iopub.execute_input": "2023-02-25T00:06:19.437295Z",
          "iopub.status.idle": "2023-02-25T00:06:19.628642Z",
          "shell.execute_reply.started": "2023-02-25T00:06:19.437257Z",
          "shell.execute_reply": "2023-02-25T00:06:19.627555Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "206f3d63"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation"
      ],
      "metadata": {
        "id": "aa963b8a",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "id": "aa963b8a"
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/radix-ai/agoro-field-boundary-detector/tree/master/src/agoro_field_boundary_detector\n",
        "def t_linear(\n",
        "    field: np.ndarray,\n",
        "    mask: np.ndarray,\n",
        "    _: int = 0,\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Apply a linear (i.e. no) transformation and save.\"\"\"\n",
        "    return field, mask\n",
        "\n",
        "def t_quartile(\n",
        "    field: np.ndarray,\n",
        "    mask: np.ndarray,\n",
        "    idx: int,\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Divide the information into four quarters.\"\"\"\n",
        "    assert idx in range(0, 3 + 1)\n",
        "    x, y = [(0, 0), (0, 1), (1, 0), (1, 1)][idx]\n",
        "    width, height = mask.shape  # 2d array\n",
        "\n",
        "    # Slice and recover shape\n",
        "    field_slice = field[\n",
        "        (width // 2) * x : (width // 2) * (x + 1), (height // 2) * y : (height // 2) * (y + 1)\n",
        "    ]\n",
        "    field_slice = field_slice.repeat(2, axis=0).repeat(2, axis=1)\n",
        "    mask_slice = mask[\n",
        "        (width // 2) * x : (width // 2) * (x + 1), (height // 2) * y : (height // 2) * (y + 1)\n",
        "    ]\n",
        "    mask_slice = mask_slice.repeat(2, axis=0).repeat(2, axis=1)\n",
        "\n",
        "    # Normalise masking values\n",
        "    values = sorted(set(np.unique(mask_slice)) - {0})\n",
        "    for idx, v in enumerate(values):\n",
        "        mask_slice[mask_slice == v] = idx + 1\n",
        "    return field_slice, mask_slice\n",
        "    \n",
        "def t_rotation(\n",
        "    field: np.ndarray,\n",
        "    mask: np.ndarray,\n",
        "    rot: int,\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Rotate the data.\"\"\"\n",
        "    assert rot in range(0, 3 + 1)\n",
        "    for _ in range(rot):\n",
        "        field = np.rot90(field)\n",
        "        mask = np.rot90(mask)\n",
        "    return field, mask\n",
        "\n",
        "def t_flip(\n",
        "    field: np.ndarray,\n",
        "    mask: np.ndarray,\n",
        "    idx: int,\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Flip the data.\"\"\"\n",
        "    assert idx in range(0, 2 + 1)\n",
        "    if idx == 0:  # Diagonal\n",
        "        field = np.rot90(np.fliplr(field))\n",
        "        mask = np.rot90(np.fliplr(mask))\n",
        "    if idx == 1:  # Horizontal\n",
        "        field = np.flip(field, axis=0)\n",
        "        mask = np.flip(mask, axis=0)\n",
        "    if idx == 2:  # Vertical\n",
        "        field = np.flip(field, axis=1)\n",
        "        mask = np.flip(mask, axis=1)\n",
        "    return field, mask\n",
        "\n",
        "def t_blur(\n",
        "    field: np.ndarray,\n",
        "    mask: np.ndarray,\n",
        "    sigma: int,\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Blur the image by applying a Gaussian filter.\"\"\"\n",
        "    assert 0 <= sigma <= 10\n",
        "    sigma_f = 1.0 + (sigma / 10)\n",
        "    field = np.copy(field)\n",
        "    for i in range(3):\n",
        "        field[:, :, i] = gaussian_filter(field[:, :, i], sigma=sigma_f)\n",
        "    return field, mask"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:19.640570Z",
          "iopub.execute_input": "2023-02-25T00:06:19.641045Z",
          "iopub.status.idle": "2023-02-25T00:06:19.659326Z",
          "shell.execute_reply.started": "2023-02-25T00:06:19.640996Z",
          "shell.execute_reply": "2023-02-25T00:06:19.658067Z"
        },
        "trusted": true,
        "id": "nD3lwxBZRmoM"
      },
      "execution_count": null,
      "outputs": [],
      "id": "nD3lwxBZRmoM"
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(field:np.ndarray, mask:np.ndarray): \n",
        "    \"\"\"Show the field and corresponding mask.\"\"\"\n",
        "    fig = plt.figure(figsize=(8,6))\n",
        "    ax1 = fig.add_subplot(121)  # left side\n",
        "    ax2 = fig.add_subplot(122)  # right side\n",
        "    ax1.imshow(field[:,:,0:3])  # rgb band\n",
        "    plt.gray()\n",
        "    ax2.imshow(mask)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "48e3c72c",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:19.662268Z",
          "iopub.execute_input": "2023-02-25T00:06:19.662838Z",
          "iopub.status.idle": "2023-02-25T00:06:19.673445Z",
          "shell.execute_reply.started": "2023-02-25T00:06:19.662782Z",
          "shell.execute_reply": "2023-02-25T00:06:19.672421Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "48e3c72c"
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(field,mask)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:19.674996Z",
          "iopub.execute_input": "2023-02-25T00:06:19.675348Z",
          "iopub.status.idle": "2023-02-25T00:06:20.137526Z",
          "shell.execute_reply.started": "2023-02-25T00:06:19.675315Z",
          "shell.execute_reply": "2023-02-25T00:06:20.135717Z"
        },
        "trusted": true,
        "id": "p3oM4rkNRmoP"
      },
      "execution_count": null,
      "outputs": [],
      "id": "p3oM4rkNRmoP"
    },
    {
      "cell_type": "code",
      "source": [
        "f,m = t_flip(field, mask, idx=0) #flipping\n",
        "show_image(f,m)"
      ],
      "metadata": {
        "id": "94751806",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:20.146273Z",
          "iopub.execute_input": "2023-02-25T00:06:20.147041Z",
          "iopub.status.idle": "2023-02-25T00:06:20.564851Z",
          "shell.execute_reply.started": "2023-02-25T00:06:20.146988Z",
          "shell.execute_reply": "2023-02-25T00:06:20.563912Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "94751806"
    },
    {
      "cell_type": "code",
      "source": [
        "f,m = t_blur(field, mask, sigma=5) #blur\n",
        "show_image(f,m)"
      ],
      "metadata": {
        "id": "d243d28c",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:20.566159Z",
          "iopub.execute_input": "2023-02-25T00:06:20.567109Z",
          "iopub.status.idle": "2023-02-25T00:06:20.982878Z",
          "shell.execute_reply.started": "2023-02-25T00:06:20.567072Z",
          "shell.execute_reply": "2023-02-25T00:06:20.981964Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "d243d28c"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(\n",
        "    field: np.ndarray,\n",
        "    mask: np.ndarray,\n",
        "    write_folder: Path,\n",
        "    prefix: str = \"\",\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Generate data augmentations of the provided field and corresponding mask which includes:\n",
        "     - Linear (no) transformation\n",
        "     - Rotation\n",
        "     - Horizontal or vertical flip\n",
        "     - Gaussian filter (blur)\n",
        "    :param field: Input array of the field to augment\n",
        "    :param mask: Input array of the corresponding mask to augment\n",
        "    :param write_folder: Folder (path) to write the results (augmentations) to\n",
        "    :param prefix: Field-specific prefix used when writing the augmentation results\n",
        "    \"\"\"\n",
        "    # Generate transformations\n",
        "    f, m = [0,1,2,3, 4], [0,1,2,3, 4] #dummy data. will be replaced\n",
        "    f[0],m[0] = t_linear(field, mask) #no augmentation\n",
        "    f[1],m[1] = t_rotation(field, mask, rot=1) #rotation\n",
        "    f[2],m[2] = t_flip(field, mask, idx=0) #flipping\n",
        "    f[3],m[3] = t_blur(field, mask, sigma=5) #blur\n",
        "    f[4],m[4] = t_quartile(field, mask, idx=1) #quartile    \n",
        "    \n",
        "    for i in range(len(f)):        \n",
        "    \n",
        "\n",
        "        with open(write_folder +'/'+ f\"fields/{str(prefix).zfill(2)}_{i}.pkl\", 'wb') as handle:\n",
        "            pickle.dump(f[i], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "        with open(write_folder +'/'+ f\"masks/{str(prefix).zfill(2)}_{i}.pkl\", 'wb') as handle:\n",
        "            pickle.dump(m[i], handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "a15fdcfe",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:20.984342Z",
          "iopub.execute_input": "2023-02-25T00:06:20.984909Z",
          "iopub.status.idle": "2023-02-25T00:06:20.997346Z",
          "shell.execute_reply.started": "2023-02-25T00:06:20.984871Z",
          "shell.execute_reply": "2023-02-25T00:06:20.996141Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "a15fdcfe"
    },
    {
      "cell_type": "code",
      "source": [
        "def main(\n",
        "    field: List[np.ndarray],\n",
        "    mask: List[np.ndarray],\n",
        "    prefix: List[str],\n",
        "    write_folder: Path,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Generate and save data augmentations for all the fields and corresponding masks with the following:\n",
        "     - Linear (no) transformation\n",
        "     - Rotation\n",
        "     - Horizontal or vertical flip\n",
        "     - Gaussian filter (blur)\n",
        "     - Gamma filter (brightness)\n",
        "    :param fields: Fields to augment\n",
        "    :param masks: Corresponding masks to augment\n",
        "    :param prefixes: Field-specific prefixes corresponding each field\n",
        "    :param write_folder: Path to write the results (augmentations) to\n",
        "    \"\"\"\n",
        "    generate(\n",
        "        field=field,\n",
        "        mask=mask,\n",
        "        prefix=prefix,\n",
        "        write_folder=write_folder,\n",
        "    )"
      ],
      "metadata": {
        "id": "926c5b65",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:21.005830Z",
          "iopub.execute_input": "2023-02-25T00:06:21.006112Z",
          "iopub.status.idle": "2023-02-25T00:06:21.012858Z",
          "shell.execute_reply.started": "2023-02-25T00:06:21.006087Z",
          "shell.execute_reply": "2023-02-25T00:06:21.011807Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "926c5b65"
    },
    {
      "cell_type": "code",
      "source": [
        "#apply augmentation effects to training set\n",
        "for tile in train_tiles:\n",
        "    bd1 = rio.open(f\"{train_source_items}/{dataset_id}_source_train_{tile}/B01.tif\")\n",
        "    bd1_array = bd1.read(1)\n",
        "    bd2 = rio.open(f\"{train_source_items}/{dataset_id}_source_train_{tile}/B02.tif\")\n",
        "    bd2_array = bd2.read(1)\n",
        "    bd3 = rio.open(f\"{train_source_items}/{dataset_id}_source_train_{tile}/B03.tif\")\n",
        "    bd3_array = bd3.read(1)\n",
        "    bd4 = rio.open(f\"{train_source_items}/{dataset_id}_source_train_{tile}/B04.tif\")\n",
        "    bd4_array = bd4.read(1)\n",
        "\n",
        "    field = np.dstack((bd4_array, bd3_array, bd2_array, bd1_array))\n",
        "\n",
        "    field = np.sqrt(field)\n",
        "\n",
        "    #data standardization\n",
        "    for c in range(field.shape[2]):\n",
        "        mean = field[:, :, c].mean()\n",
        "        std = field[:, :, c].std()\n",
        "        field[:, :, c] = (field[:, :, c] - mean) / std\n",
        "\n",
        "\n",
        "    ids_list  = tile.split('_') # XX_YYYY_MM where XX is the training file id and YYYY_MM is the timestamp\n",
        "    tile_id   = ids_list[0]\n",
        "    timestamp = f\"{ids_list[1]}_{ids_list[2]}\"\n",
        "\n",
        "    mask  = rio.open(Path.cwd() / f\"{train_label_items}/{dataset_id}_labels_train_{tile_id}/raster_labels.tif\").read(1) \n",
        "\n",
        "    #create a folder for the augmented images\n",
        "    if not os.path.isdir(f\"./train_data/{timestamp}\"):\n",
        "        os.makedirs(f\"./train_data/{timestamp}\")\n",
        "    if not os.path.isdir(f\"./train_data/{timestamp}/fields\"):\n",
        "        os.makedirs(f\"./train_data/{timestamp}/fields\")\n",
        "    if not os.path.isdir(f\"./train_data/{timestamp}/masks\"):\n",
        "        os.makedirs(f\"./train_data/{timestamp}/masks\")\n",
        "\n",
        "    main( #applying augmentation effects\n",
        "        field  = field,\n",
        "        mask   = mask,\n",
        "        prefix = tile_id,\n",
        "        write_folder = f\"./train_data/{timestamp}\",\n",
        "    ) "
      ],
      "metadata": {
        "id": "a25f4264",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:21.014749Z",
          "iopub.execute_input": "2023-02-25T00:06:21.015462Z",
          "iopub.status.idle": "2023-02-25T00:06:35.384735Z",
          "shell.execute_reply.started": "2023-02-25T00:06:21.015428Z",
          "shell.execute_reply": "2023-02-25T00:06:35.383772Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "a25f4264"
    },
    {
      "cell_type": "code",
      "source": [
        "timestamps = next(os.walk(f\"./train_data\"))[1] #Get all timestamps\n",
        "augmented_files = next(os.walk(f\"./train_data/{timestamps[0]}/fields\"))[2] #Get all augmented tile ids. can just use one timestamp\n",
        "X = np.empty((len(augmented_files), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS*len(timestamps)), dtype=np.float32) #time-series image\n",
        "y = np.empty((len(augmented_files), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8) #mask for each scene\n",
        "i = 0\n",
        "for file in augmented_files:\n",
        "    idx = 0\n",
        "    augmented_id = file.split('.pkl')[0] #id without .pkl extension\n",
        "    temporal_fields = []\n",
        "    for timestamp in timestamps:\n",
        "        with open(f\"./train_data/{timestamp}/fields/{augmented_id}.pkl\", 'rb') as field:\n",
        "            field = pickle.load(field) \n",
        "            \n",
        "        X[i][:,:,idx:idx+IMG_CHANNELS] = field\n",
        "        idx += IMG_CHANNELS\n",
        "    with open(f\"./train_data/{timestamp}/masks/{augmented_id}.pkl\", 'rb') as mask:\n",
        "        mask = pickle.load(mask)\n",
        "    y[i] = mask.reshape(IMG_HEIGHT, IMG_WIDTH, 1)\n",
        "    i+=1"
      ],
      "metadata": {
        "id": "4e863113",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:35.385945Z",
          "iopub.execute_input": "2023-02-25T00:06:35.386315Z",
          "iopub.status.idle": "2023-02-25T00:06:38.785505Z",
          "shell.execute_reply.started": "2023-02-25T00:06:35.386281Z",
          "shell.execute_reply": "2023-02-25T00:06:38.784182Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "4e863113"
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "yWB4L03O9ZxL",
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:38.786962Z",
          "iopub.execute_input": "2023-02-25T00:06:38.787366Z",
          "iopub.status.idle": "2023-02-25T00:06:38.793917Z",
          "shell.execute_reply.started": "2023-02-25T00:06:38.787327Z",
          "shell.execute_reply": "2023-02-25T00:06:38.793035Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "yWB4L03O9ZxL"
    },
    {
      "cell_type": "code",
      "source": [
        "random.randint(0, len(augmented_files)) #sanity check\n",
        "random_image = random.randint(0, len(augmented_files)-1)\n",
        "show_image(X[random_image][:,:,0:3], y[random_image].reshape(IMG_WIDTH, IMG_HEIGHT))"
      ],
      "metadata": {
        "id": "6bf7797a",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:38.795346Z",
          "iopub.execute_input": "2023-02-25T00:06:38.795905Z",
          "iopub.status.idle": "2023-02-25T00:06:39.745170Z",
          "shell.execute_reply.started": "2023-02-25T00:06:38.795870Z",
          "shell.execute_reply": "2023-02-25T00:06:39.744272Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "6bf7797a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scheduler"
      ],
      "metadata": {
        "id": "GV6VbdeClmbt"
      },
      "id": "GV6VbdeClmbt"
    },
    {
      "cell_type": "code",
      "source": [
        "class SGDRScheduler(tf.keras.callbacks.Callback):\n",
        "    '''Cosine annealing learning rate scheduler with periodic restarts.\n",
        "    # Usage\n",
        "        ```python\n",
        "            schedule = SGDRScheduler(min_lr=1e-5,\n",
        "                                     max_lr=1e-2,\n",
        "                                     steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
        "                                     lr_decay=0.9,\n",
        "                                     cycle_length=5,\n",
        "                                     mult_factor=1.5)\n",
        "            model.fit(X_train, Y_train, epochs=100, callbacks=[schedule])\n",
        "        ```\n",
        "    # Arguments\n",
        "        min_lr: The lower bound of the learning rate range for the experiment.\n",
        "        max_lr: The upper bound of the learning rate range for the experiment.\n",
        "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`. \n",
        "        lr_decay: Reduce the max_lr after the completion of each cycle.\n",
        "                  Ex. To reduce the max_lr by 20% after each cycle, set this value to 0.8.\n",
        "        cycle_length: Initial number of epochs in a cycle.\n",
        "        mult_factor: Scale epochs_to_restart after each full cycle completion.\n",
        "    # References\n",
        "        Blog post: jeremyjordan.me/nn-learning-rate\n",
        "        Original paper: http://arxiv.org/abs/1608.03983\n",
        "    '''\n",
        "    def __init__(self,\n",
        "                 min_lr,\n",
        "                 max_lr,\n",
        "                 steps_per_epoch,\n",
        "                 lr_decay=1,\n",
        "                 cycle_length=10,\n",
        "                 mult_factor=2):\n",
        "\n",
        "        self.min_lr = min_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.lr_decay = lr_decay\n",
        "\n",
        "        self.batch_since_restart = 0\n",
        "        self.next_restart = cycle_length\n",
        "\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "\n",
        "        self.cycle_length = cycle_length\n",
        "        self.mult_factor = mult_factor\n",
        "\n",
        "        self.history = {}\n",
        "\n",
        "    def clr(self):\n",
        "        '''Calculate the learning rate.'''\n",
        "        fraction_to_restart = self.batch_since_restart / (self.steps_per_epoch * self.cycle_length)\n",
        "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(fraction_to_restart * np.pi))\n",
        "        return lr\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
        "        logs = logs or {}\n",
        "        K.set_value(self.model.optimizer.lr, self.max_lr)\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        '''Record previous batch statistics and update the learning rate.'''\n",
        "        logs = logs or {}\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "\n",
        "        self.batch_since_restart += 1\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        '''Check for end of current cycle, apply restarts when necessary.'''\n",
        "        if epoch + 1 == self.next_restart:\n",
        "            self.batch_since_restart = 0\n",
        "            self.cycle_length = np.ceil(self.cycle_length * self.mult_factor)\n",
        "            self.next_restart += self.cycle_length\n",
        "            self.max_lr *= self.lr_decay\n",
        "            self.best_weights = self.model.get_weights()\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        '''Set weights to the values from the end of the most recent cycle for best performance.'''\n",
        "        self.model.set_weights(self.best_weights)"
      ],
      "metadata": {
        "id": "f03c85a9",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:39.753754Z",
          "iopub.execute_input": "2023-02-25T00:06:39.754538Z",
          "iopub.status.idle": "2023-02-25T00:06:39.769264Z",
          "shell.execute_reply.started": "2023-02-25T00:06:39.754503Z",
          "shell.execute_reply": "2023-02-25T00:06:39.768447Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "f03c85a9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Hyperparameters"
      ],
      "metadata": {
        "id": "IozwLshOlTfw"
      },
      "id": "IozwLshOlTfw"
    },
    {
      "cell_type": "code",
      "source": [
        "BACKBONE = 'efficientnetb7'\n",
        "\n",
        "\n",
        "num_channels = 24\n",
        "input_shape = (256,256,num_channels)\n",
        "\n",
        "\n",
        "BATCH_SIZE = 4 \n",
        "\n",
        "LR = 1e-4\n",
        "\n",
        "N_EPOCHS = 50\n",
        "\n",
        "MIN_LR = 1e-6\n",
        "\n",
        "MAX_LR = 1e-2\n",
        "\n",
        "MULTI_FACTOR = 1.5\n",
        "\n",
        "DECAY_RATE = 0.85\n",
        "\n",
        "WEIGHT_DECAY = 1e-5"
      ],
      "metadata": {
        "id": "d678f3a4",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:39.787206Z",
          "iopub.execute_input": "2023-02-25T00:06:39.787558Z",
          "iopub.status.idle": "2023-02-25T00:06:39.799933Z",
          "shell.execute_reply.started": "2023-02-25T00:06:39.787524Z",
          "shell.execute_reply": "2023-02-25T00:06:39.798841Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "d678f3a4"
    },
    {
      "cell_type": "code",
      "source": [
        "#https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
        "def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "def f1(y_true, y_pred):\n",
        "    def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall_   = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall_)/(precision+recall_+K.epsilon()))"
      ],
      "metadata": {
        "id": "eeb17518",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:39.801830Z",
          "iopub.execute_input": "2023-02-25T00:06:39.802142Z",
          "iopub.status.idle": "2023-02-25T00:06:39.812797Z",
          "shell.execute_reply.started": "2023-02-25T00:06:39.802117Z",
          "shell.execute_reply": "2023-02-25T00:06:39.811761Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "eeb17518"
    },
    {
      "cell_type": "code",
      "source": [
        "# Combo Loss - Dice + Binary crossentropy\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1.0):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def binary_crossentropy(y, p):\n",
        "    return K.mean(K.binary_crossentropy(y, p))\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1 - dice_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "def dice_coef_loss_bce(y_true, y_pred, dice=0.5, bce=0.5):\n",
        "    return binary_crossentropy(y_true, y_pred) * bce + dice_coef_loss(y_true, y_pred) * dice\n",
        "\n",
        "def bce_dice_loss(y, p):\n",
        "    return dice_coef_loss_bce(y, p, dice=0.9, bce=0.1)"
      ],
      "metadata": {
        "id": "kjIPQOnTY5JN",
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:39.936499Z",
          "iopub.execute_input": "2023-02-25T00:06:39.936841Z",
          "iopub.status.idle": "2023-02-25T00:06:39.944331Z",
          "shell.execute_reply.started": "2023-02-25T00:06:39.936804Z",
          "shell.execute_reply": "2023-02-25T00:06:39.943046Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "kjIPQOnTY5JN"
    },
    {
      "cell_type": "code",
      "source": [
        "sm.set_framework('tf.keras')\n",
        "sm.framework()\n",
        "\n",
        "def get_model():\n",
        "    model = None \n",
        "    model_unet = Unet(BACKBONE, encoder_weights='imagenet')\n",
        "    new_model = keras.models.Sequential()\n",
        "    new_model.add(Conv2D(3, (1,1), padding='same', activation='relu', input_shape=input_shape))\n",
        "    new_model.add(model_unet)\n",
        "    model = new_model \n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "078b398a",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:40.554611Z",
          "iopub.execute_input": "2023-02-25T00:06:40.554960Z",
          "iopub.status.idle": "2023-02-25T00:06:40.563636Z",
          "shell.execute_reply.started": "2023-02-25T00:06:40.554926Z",
          "shell.execute_reply": "2023-02-25T00:06:40.562557Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "078b398a"
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental_run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "611d6eca",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:40.801322Z",
          "iopub.execute_input": "2023-02-25T00:06:40.802457Z",
          "iopub.status.idle": "2023-02-25T00:06:40.807729Z",
          "shell.execute_reply.started": "2023-02-25T00:06:40.802420Z",
          "shell.execute_reply": "2023-02-25T00:06:40.806714Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "611d6eca"
    },
    {
      "cell_type": "code",
      "source": [
        "# reference : https://www.kaggle.com/code/giselama/5-1-multilabel-semantic-segmentation\n",
        "\n",
        "def stratified_split(x, y, val_size = 0.2, kFold=5):\n",
        "    ind = np.arange(len(y))\n",
        "    np.random.shuffle(ind)\n",
        "    coverage = []\n",
        "    for i in range(0, len(y)):\n",
        "        coverage.append(np.sum(y[ind[i]]))\n",
        "\n",
        "    hist, bin_edges = np.histogram(coverage)\n",
        "    bin_edges[len(bin_edges)-1] = bin_edges[len(bin_edges)-1] + 1\n",
        "    cindex = np.digitize(coverage,bin_edges)\n",
        "\n",
        "    val_size = val_size\n",
        "    for ii in range(kFold): #5-fold learning\n",
        "        k = ii\n",
        "        train_idxs = []\n",
        "        val_idxs = []\n",
        "        for i in range(0,10):\n",
        "            index_temp = ind[cindex==i+1]\n",
        "            list_temp = index_temp.T.tolist()\n",
        "            val_samples = round(len(index_temp)*val_size)\n",
        "            if (k == 0):\n",
        "                val_idxs = val_idxs + list_temp[:val_samples]\n",
        "                train_idxs = train_idxs + list_temp[val_samples:]\n",
        "            elif (k == 4):\n",
        "                val_idxs = val_idxs + list_temp[4*val_samples:]\n",
        "                train_idxs = train_idxs + list_temp[:4*val_samples]\n",
        "            else:\n",
        "                val_idxs = val_idxs + list_temp[k*val_samples:(k+1)*val_samples]\n",
        "                train_idxs = train_idxs + list_temp[:k*val_samples] + list_temp[(k+1)*val_samples:]\n",
        "\n",
        "        val_idxs = ind[val_idxs]\n",
        "        train_idxs = ind[train_idxs]\n",
        "\n",
        "    return x[train_idxs],y[train_idxs],x[val_idxs],y[val_idxs]\n"
      ],
      "metadata": {
        "id": "6LpILFEu_CXt"
      },
      "id": "6LpILFEu_CXt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Train and Validation splits"
      ],
      "metadata": {
        "id": "DD27nFSLkKhF"
      },
      "id": "DD27nFSLkKhF"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train,X_valid, y_valid  = stratified_split(X, y, val_size = 0.2, kFold=5)"
      ],
      "metadata": {
        "id": "HQoDfjaI_Rmn"
      },
      "id": "HQoDfjaI_Rmn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_valid.shape"
      ],
      "metadata": {
        "id": "MLMJeKwPBSJV"
      },
      "id": "MLMJeKwPBSJV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import ndimage"
      ],
      "metadata": {
        "id": "X6P0T2ZnpCSf"
      },
      "id": "X6P0T2ZnpCSf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all train tiles\n",
        "\n",
        "bands_arr = np.zeros((len(train_tiles), IMG_HEIGHT, IMG_WIDTH, 4), dtype = np.float32)\n",
        "\n",
        "for tid, tile in enumerate(train_tiles):\n",
        "\n",
        "    bd1 = rio.open(f\"{train_source_items}/{dataset_id}_source_train_{tile}/B01.tif\")\n",
        "    bd1_array = bd1.read(1)\n",
        "    bd2 = rio.open(f\"{train_source_items}/{dataset_id}_source_train_{tile}/B02.tif\")\n",
        "    bd2_array = bd2.read(1)\n",
        "    bd3 = rio.open(f\"{train_source_items}/{dataset_id}_source_train_{tile}/B03.tif\")\n",
        "    bd3_array = bd3.read(1)\n",
        "    bd4 = rio.open(f\"{train_source_items}/{dataset_id}_source_train_{tile}/B04.tif\")\n",
        "    bd4_array = bd4.read(1)\n",
        "\n",
        "    bands_arr[tid] = np.dstack((bd4_array, bd3_array, bd2_array, bd1_array))\n",
        "    \n",
        "\n",
        "bands_arr = np.sqrt(bands_arr)\n",
        "\n",
        "#data standardization\n",
        "for c in range(bands_arr.shape[-1]):\n",
        "    mean = bands_arr[:, :, :, c].mean()\n",
        "    std = bands_arr[:, :, :, c].std()\n",
        "    bands_arr[:, :, :, c] = (bands_arr[:, :, :, c] - mean) / std\n",
        "\n",
        "\n",
        "\n",
        "tiles = bands_arr.copy()\n",
        "\n",
        "del bands_arr\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "id": "Zmm-R8D4o9WB"
      },
      "id": "Zmm-R8D4o9WB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mixup Data Augmentation"
      ],
      "metadata": {
        "id": "DTsWwLDwkQNq"
      },
      "id": "DTsWwLDwkQNq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapted from : https://github.com/radiantearth/CropDetectionDL/blob/main/dataset.py\n",
        "\n",
        "def augment(img, mask):       \n",
        "\n",
        "    p = np.random.random(3)\n",
        "    ang = np.random.uniform(-10, 10)\n",
        "\n",
        "    #mixup training image with a random crop from the tiles\n",
        "    if (p[0] > 0.5):\n",
        "        start_x = np.random.randint(0, bands_arr.shape[1] - 32)\n",
        "        start_y = np.random.randint(0, bands_arr.shape[2] - 32)\n",
        "        t = np.random.randint(0, 342)\n",
        "        rnd_crop = tiles[t] # randomly sample a tile\n",
        "        d = 0.85\n",
        "\n",
        "        img = img.reshape(6, IMG_WIDTH, IMG_HEIGHT, 4)\n",
        "        img = img * d + rnd_crop * (1 - d)\n",
        "\n",
        "        img = img.reshape(IMG_WIDTH, IMG_HEIGHT, 24)\n",
        "\n",
        "\n",
        "    #apply flipping and rotation augmentation\n",
        "\n",
        "    if p[1] > 0.5:\n",
        "        mask[0] = np.flipud(mask[0])\n",
        "    if p[2] > 0.5:\n",
        "        mask = ndimage.rotate(mask, ang, reshape = False)        \n",
        "    for i in range(img.shape[0]):\n",
        "        for j in range(img.shape[1]):\n",
        "            if p[1] > 0.5:\n",
        "                img[i,j] = np.flipud(img[i,j])\n",
        "\n",
        "    return img, mask"
      ],
      "metadata": {
        "id": "rczz0aaJna8g"
      },
      "id": "rczz0aaJna8g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain_aug2, ytrain2 =[],[]\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    \n",
        "    xx, yy = augment(X_train[i], y_train[i])\n",
        "    \n",
        "    xtrain_aug2.append(xx)\n",
        "    ytrain2.append(yy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-25T00:06:47.031089Z",
          "iopub.execute_input": "2023-02-25T00:06:47.031569Z",
          "iopub.status.idle": "2023-02-25T00:07:11.328086Z",
          "shell.execute_reply.started": "2023-02-25T00:06:47.031533Z",
          "shell.execute_reply": "2023-02-25T00:07:11.327079Z"
        },
        "trusted": true,
        "id": "H3d3H1zmRmpf"
      },
      "execution_count": null,
      "outputs": [],
      "id": "H3d3H1zmRmpf"
    },
    {
      "cell_type": "code",
      "source": [
        "X_augmented =   np.array(xtrain_aug2, dtype = np.float32)\n",
        "Y_augmented = np.array(ytrain2,  dtype = np.float32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-25T00:07:11.566939Z",
          "iopub.execute_input": "2023-02-25T00:07:11.567732Z",
          "iopub.status.idle": "2023-02-25T00:07:13.519253Z",
          "shell.execute_reply.started": "2023-02-25T00:07:11.567681Z",
          "shell.execute_reply": "2023-02-25T00:07:13.518222Z"
        },
        "trusted": true,
        "id": "Yq1gFYNsRmpg"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Yq1gFYNsRmpg"
    },
    {
      "cell_type": "code",
      "source": [
        "X_augmented.shape, Y_augmented.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-25T00:07:13.520656Z",
          "iopub.execute_input": "2023-02-25T00:07:13.521142Z",
          "iopub.status.idle": "2023-02-25T00:07:13.530683Z",
          "shell.execute_reply.started": "2023-02-25T00:07:13.521100Z",
          "shell.execute_reply": "2023-02-25T00:07:13.529453Z"
        },
        "trusted": true,
        "id": "NrzdJ1YXRmph"
      },
      "execution_count": null,
      "outputs": [],
      "id": "NrzdJ1YXRmph"
    },
    {
      "cell_type": "code",
      "source": [
        "del  xtrain_aug2,ytrain2\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-25T00:07:13.532389Z",
          "iopub.execute_input": "2023-02-25T00:07:13.533414Z",
          "iopub.status.idle": "2023-02-25T00:07:13.580751Z",
          "shell.execute_reply.started": "2023-02-25T00:07:13.533366Z",
          "shell.execute_reply": "2023-02-25T00:07:13.579796Z"
        },
        "trusted": true,
        "id": "HylNazOCRmpi"
      },
      "execution_count": null,
      "outputs": [],
      "id": "HylNazOCRmpi"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.vstack((X_train, X_augmented))\n",
        "y_train = np.vstack((y_train, Y_augmented))"
      ],
      "metadata": {
        "id": "_6YpZoa8_xme"
      },
      "id": "_6YpZoa8_xme",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "id": "kC31HmgoBjx2"
      },
      "id": "kC31HmgoBjx2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "pA0_gBbHkyV4"
      },
      "id": "pA0_gBbHkyV4"
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything(seed=2023)\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "y_valid = tf.cast(y_valid, tf.float32)\n",
        "y_train = tf.cast(y_train, tf.float32)   \n",
        "\n",
        "mc = ModelCheckpoint(f'./best_model.h5', monitor='val_f1', verbose=0, save_best_only=True,\n",
        "                                    save_weights_only=True, mode='max')\n",
        "\n",
        "sched = SGDRScheduler(min_lr= MIN_LR,\n",
        "                                  max_lr=MAX_LR,\n",
        "                                  steps_per_epoch=np.ceil(N_EPOCHS/BATCH_SIZE),\n",
        "                                  lr_decay=DECAY_RATE,\n",
        "                                  mult_factor=MULTI_FACTOR)\n",
        "\n",
        "cbs = [sched, mc]\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "model.compile(loss= bce_dice_loss,\n",
        "              optimizer=tfa.optimizers.AdamW(learning_rate=LR, weight_decay=WEIGHT_DECAY),\n",
        "              metrics=[f1, recall])\n",
        "\n",
        "history = model.fit(X_train,y_train,\n",
        "              validation_data=(X_valid, y_valid),batch_size = BATCH_SIZE,\n",
        "              steps_per_epoch = len(X_train)//BATCH_SIZE,\n",
        "              validation_steps = np.ceil(len(X_valid)/BATCH_SIZE), epochs=N_EPOCHS,\n",
        "              callbacks=cbs)\n",
        "\n",
        "del model, X_train, X_valid, y_train, y_valid\n",
        "_ =gc.collect()\n",
        "\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label=f'Fold {fold} Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Fold {fold} Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "recall_score = history.history['recall']\n",
        "val_recall_score = history.history['val_recall']\n",
        "epochs = range(1, len(recall_score) + 1)\n",
        "plt.plot(epochs, recall_score, 'y', label=f'Fold {fold} Training recall')\n",
        "plt.plot(epochs, val_recall_score, 'r', label=f'Fold {fold} Validation recall')\n",
        "plt.title('Training and validation Recall')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Recall')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "f1score = history.history['f1']\n",
        "val_f1score = history.history['val_f1']\n",
        "epochs = range(1, len(f1score) + 1)\n",
        "plt.plot(epochs, f1score, 'y', label=f'Fold {fold} Training f1')\n",
        "plt.plot(epochs, val_f1score, 'r', label=f'Fold {fold} Validation f1')\n",
        "plt.title('Training and validation f1')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('f1 ')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "del history\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "id": "4cd892e6",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-25T00:07:14.011054Z",
          "iopub.execute_input": "2023-02-25T00:07:14.011471Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "4cd892e6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading test chips to run predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "77ecac4e",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "id": "77ecac4e"
    },
    {
      "cell_type": "code",
      "source": [
        "test_source_items = f\"{dataset_id}/{dataset_id}_source_test\"\n",
        "test_tiles = [clean_string(s) for s in next(os.walk(test_source_items))[1]]"
      ],
      "metadata": {
        "id": "780e5f21",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-24T23:23:14.140800Z",
          "iopub.execute_input": "2023-02-24T23:23:14.141164Z",
          "iopub.status.idle": "2023-02-24T23:23:14.148705Z",
          "shell.execute_reply.started": "2023-02-24T23:23:14.141133Z",
          "shell.execute_reply": "2023-02-24T23:23:14.147592Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "780e5f21"
    },
    {
      "cell_type": "code",
      "source": [
        "test_tile_ids = set()\n",
        "for tile in test_tiles:\n",
        "    test_tile_ids.add(tile.split('_')[0])"
      ],
      "metadata": {
        "id": "b343d453",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-24T23:23:15.849586Z",
          "iopub.execute_input": "2023-02-24T23:23:15.849953Z",
          "iopub.status.idle": "2023-02-24T23:23:15.855128Z",
          "shell.execute_reply.started": "2023-02-24T23:23:15.849923Z",
          "shell.execute_reply": "2023-02-24T23:23:15.854127Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "b343d453"
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.empty((len(test_tile_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS*len(timestamps)), dtype=np.float32)\n",
        "i = 0\n",
        "loaded_tiles = []\n",
        "for tile_id in test_tile_ids:\n",
        "    idx = 0\n",
        "    for timestamp in timestamps:\n",
        "        bd1 = rio.open(f\"{test_source_items}/{dataset_id}_source_test_{tile_id}_{timestamp}/B01.tif\")\n",
        "        bd1_array = bd1.read(1)\n",
        "        bd2 = rio.open(f\"{test_source_items}/{dataset_id}_source_test_{tile_id}_{timestamp}/B02.tif\")\n",
        "        bd2_array = bd2.read(1)\n",
        "        bd3 = rio.open(f\"{test_source_items}/{dataset_id}_source_test_{tile_id}_{timestamp}/B03.tif\")\n",
        "        bd3_array = bd3.read(1)\n",
        "        bd4 = rio.open(f\"{test_source_items}/{dataset_id}_source_test_{tile_id}_{timestamp}/B04.tif\")\n",
        "        bd4_array = bd4.read(1)\n",
        "\n",
        "        field = np.dstack((bd4_array, bd3_array, bd2_array, bd1_array))\n",
        "\n",
        "\n",
        "        field = np.sqrt(field)\n",
        "\n",
        "        #data standardization\n",
        "        for c in range(field.shape[2]):\n",
        "            mean = field[:, :, c].mean()\n",
        "            std = field[:, :, c].std()\n",
        "            field[:, :, c] = (field[:, :, c] - mean) / std\n",
        "            \n",
        "        X_test[i][:,:,idx:idx+IMG_CHANNELS] = field\n",
        "        idx+=IMG_CHANNELS\n",
        "    loaded_tiles.append(str(tile_id).zfill(2)) #track order test tiles are loaded into X to make sure tile id matches \n",
        "    i+=1"
      ],
      "metadata": {
        "id": "cinmIBPmH7oa",
        "execution": {
          "iopub.status.busy": "2023-02-24T23:23:22.660208Z",
          "iopub.execute_input": "2023-02-24T23:23:22.660932Z",
          "iopub.status.idle": "2023-02-24T23:23:24.298261Z",
          "shell.execute_reply.started": "2023-02-24T23:23:22.660892Z",
          "shell.execute_reply": "2023-02-24T23:23:24.297294Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "cinmIBPmH7oa"
    },
    {
      "cell_type": "code",
      "source": [
        "# load best model to run predictions\n",
        "\n",
        "model.load_weights(\"./best_model.h5\")\n",
        "\n",
        "preds = model.predict(X_test, verbose=1, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "FTnHySQ06SYu",
        "execution": {
          "iopub.status.busy": "2023-02-24T23:23:28.203202Z",
          "iopub.execute_input": "2023-02-24T23:23:28.204245Z",
          "iopub.status.idle": "2023-02-24T23:23:29.684625Z",
          "shell.execute_reply.started": "2023-02-24T23:23:28.204205Z",
          "shell.execute_reply": "2023-02-24T23:23:29.683480Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "FTnHySQ06SYu"
    },
    {
      "cell_type": "code",
      "source": [
        "preds.shape"
      ],
      "metadata": {
        "id": "gMjJfs4OQxYS",
        "execution": {
          "iopub.status.busy": "2023-02-24T23:23:29.687096Z",
          "iopub.execute_input": "2023-02-24T23:23:29.687532Z",
          "iopub.status.idle": "2023-02-24T23:23:29.695334Z",
          "shell.execute_reply.started": "2023-02-24T23:23:29.687491Z",
          "shell.execute_reply": "2023-02-24T23:23:29.694307Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "gMjJfs4OQxYS"
    },
    {
      "cell_type": "code",
      "source": [
        "preds.min(), preds.max()"
      ],
      "metadata": {
        "id": "MdfrdmkSRknM",
        "execution": {
          "iopub.status.busy": "2023-02-24T23:23:31.475799Z",
          "iopub.execute_input": "2023-02-24T23:23:31.476545Z",
          "iopub.status.idle": "2023-02-24T23:23:31.485165Z",
          "shell.execute_reply.started": "2023-02-24T23:23:31.476484Z",
          "shell.execute_reply": "2023-02-24T23:23:31.484008Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "MdfrdmkSRknM"
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.clip(preds, 0.0001, 0.9999)"
      ],
      "metadata": {
        "id": "6QB6AFHNRCYU",
        "execution": {
          "iopub.status.busy": "2023-02-24T23:23:34.759812Z",
          "iopub.execute_input": "2023-02-24T23:23:34.760178Z",
          "iopub.status.idle": "2023-02-24T23:23:34.765904Z",
          "shell.execute_reply.started": "2023-02-24T23:23:34.760147Z",
          "shell.execute_reply": "2023-02-24T23:23:34.764820Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "6QB6AFHNRCYU"
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_dictionary = {}\n",
        "for i in range(len(test_tile_ids)):\n",
        "    model_pred = preds[i]\n",
        "    model_pred = (model_pred >= 0.5).astype(np.uint8)\n",
        "    model_pred = model_pred.reshape(IMG_HEIGHT, IMG_WIDTH)\n",
        "    predictions_dictionary.update([(str(loaded_tiles[i]), pd.DataFrame(model_pred))])"
      ],
      "metadata": {
        "id": "a122abd5",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-24T23:23:44.337217Z",
          "iopub.execute_input": "2023-02-24T23:23:44.337622Z",
          "iopub.status.idle": "2023-02-24T23:23:44.348904Z",
          "shell.execute_reply.started": "2023-02-24T23:23:44.337588Z",
          "shell.execute_reply": "2023-02-24T23:23:44.347856Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "a122abd5"
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = []\n",
        "for key, value in predictions_dictionary.items():\n",
        "    ftd = value.unstack().reset_index().rename(columns={'level_0': 'row', 'level_1': 'column', 0: 'label'})\n",
        "    ftd['tile_row_column'] = f'Tile{key}_' + ftd['row'].astype(str) + '_' + ftd['column'].astype(str)\n",
        "    ftd = ftd[['tile_row_column', 'label']]\n",
        "    dfs.append(ftd)\n",
        "\n",
        "sub = pd.concat(dfs)\n",
        "sub"
      ],
      "metadata": {
        "id": "e59ab20a",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-02-24T23:23:47.955611Z",
          "iopub.execute_input": "2023-02-24T23:23:47.955979Z",
          "iopub.status.idle": "2023-02-24T23:23:49.121502Z",
          "shell.execute_reply.started": "2023-02-24T23:23:47.955947Z",
          "shell.execute_reply": "2023-02-24T23:23:49.120514Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "e59ab20a"
    },
    {
      "cell_type": "code",
      "source": [
        "sub.label.value_counts()"
      ],
      "metadata": {
        "id": "lddvkZjrQtDG",
        "execution": {
          "iopub.status.busy": "2023-02-24T23:23:50.206501Z",
          "iopub.execute_input": "2023-02-24T23:23:50.206880Z",
          "iopub.status.idle": "2023-02-24T23:23:50.223915Z",
          "shell.execute_reply.started": "2023-02-24T23:23:50.206848Z",
          "shell.execute_reply": "2023-02-24T23:23:50.222945Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "lddvkZjrQtDG"
    },
    {
      "cell_type": "code",
      "source": [
        "sub.to_csv(\"sub_b7.csv\", index = False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-24T23:24:26.085057Z",
          "iopub.execute_input": "2023-02-24T23:24:26.085530Z",
          "iopub.status.idle": "2023-02-24T23:24:26.886315Z",
          "shell.execute_reply.started": "2023-02-24T23:24:26.085489Z",
          "shell.execute_reply": "2023-02-24T23:24:26.885209Z"
        },
        "trusted": true,
        "id": "zzsL65wBRmpy"
      },
      "execution_count": null,
      "outputs": [],
      "id": "zzsL65wBRmpy"
    }
  ]
}